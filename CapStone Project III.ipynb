{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project III: Sentiment Analysis of IMDB reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a Sentiment Analysis for reviews of movies from the IMDB data set. The data set contains a collection of 50 000 reviews, evenly split between positive and negative reviews (25,000 positive and 25,000negative reviews). A negative review is defined as having a score of <= 4 out of 10, and a positive review has a score of >= 7 out of 10. Neutral reviews(scores  between 4 and 7) have not been included in the datatset. \n",
    "\n",
    "The aim of this analysis is to create a model which will be able to distinguish between positive and negative reviews. To accomplish this, we will be creating a Recurrent Neural Network in Keras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import relevant libraries\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, Flatten, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "# import the data set from Keras\n",
    "from keras.datasets import imdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data set\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.imdb.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has already been pre-processed. By printing one review, we see that all the words in the review has been mapped to integers. Note that the integers represent words sorted by their frequency. The label, which is also an integer, represents whether the review was negative(0) or positive(1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---review---\n",
      "[1, 13, 391, 1786, 8, 97, 6, 20, 15, 9, 5057, 5, 275, 13, 391, 4, 960, 2215, 795, 15, 14, 9, 6, 717, 2717, 20, 61, 213, 9, 17, 515, 17, 14, 20, 1054, 61, 86, 931, 16, 14, 9, 51, 571, 54, 6, 1026, 2549, 494, 8, 30, 6, 20, 323, 5, 47, 57, 676, 59, 1077, 65681, 278, 8, 97, 6, 20, 59, 1040, 4189, 5, 4104, 18, 540, 8, 491, 8, 4, 20, 8, 923, 50, 16, 57, 109, 943, 5, 57, 5069, 141, 17, 6, 454, 655, 5, 277, 4, 14772, 173, 16, 52, 5, 5057, 21, 51, 16, 4, 213, 13, 219, 6, 372, 140, 8, 6, 313, 169, 49, 1268, 5817, 4, 7541, 216, 46, 499, 23, 6, 55, 1043, 314, 24, 867, 8, 808, 23, 3361, 5, 1129, 120, 41, 7541, 1461, 20, 630, 49, 31, 12854, 61, 4447, 70321, 13, 66, 181, 8, 124, 51, 4, 213, 9, 51, 16, 4, 17839, 1772, 138, 57, 943, 7, 4, 351, 1461, 138, 57, 978, 23, 4, 7541, 51, 9, 4, 213, 7, 4, 314, 1772, 51, 9, 4, 213, 7, 4, 13430, 23, 4, 519, 138, 6, 351, 7541, 138, 376, 178, 44, 35, 3954, 1752, 3127, 14329, 827, 803, 19, 4, 47060, 449, 5, 4, 13155, 9, 15, 1408, 8, 24720, 61475, 313, 14, 9, 21308, 138, 138, 62, 4, 7541, 235, 40, 45, 27, 313, 15, 1251, 16, 115, 7062, 17, 18, 1024, 23102, 13, 1610, 14, 20, 88, 29, 16, 11, 12, 5, 573, 18, 5057, 105, 901, 145, 5, 81, 376, 72, 51, 13, 359, 8, 850, 13, 244, 43, 6, 1633, 11, 655, 938, 37, 1388, 102, 1378]\n",
      "---label---\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print('---review---')\n",
    "print(X_train[15000])\n",
    "print('---label---')\n",
    "print(y_train[15000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also map the review back to words, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---review with words---\n",
      "['the', 'was', 'terrible', 'torture', 'in', 'could', 'is', 'on', 'for', 'it', 'greg', 'to', 'money', 'was', 'terrible', 'of', 'e', 'chosen', 'avoid', 'for', 'as', 'it', 'is', 'sequence', 'position', 'on', 'only', 'come', 'it', 'movie', 'sometimes', 'movie', 'as', 'on', 'filmmakers', 'only', 'how', 'sounds', 'with', 'as', 'it', 'when', 'involved', 'no', 'is', 'list', 'occasional', 'tries', 'in', 'at', 'is', 'on', 'idea', 'to', 'there', 'even', 'turned', 'would', 'la', \"'humour'\", 'sense', 'in', 'could', 'is', 'on', 'would', 'cold', 'cheating', 'to', 'dating', 'but', 'city', 'in', 'wants', 'in', 'of', 'on', 'in', 'society', 'more', 'with', 'even', 'being', 'quickly', 'to', 'even', 'spider', 'should', 'movie', 'is', '5', 'husband', 'to', 'once', 'of', \"fuller's\", 'lot', 'with', 'very', 'to', 'greg', 'not', 'when', 'with', 'of', 'come', 'was', 'least', 'is', 'next', 'through', 'in', 'is', 'everyone', 'same', 'good', 'appeal', 'renaissance', 'of', 'shin', 'saw', 'some', 'able', 'are', 'is', 'time', 'mentioned', 'left', 'his', 'sit', 'in', 'season', 'are', 'videos', 'to', 'cat', 'show', 'about', 'shin', 'offer', 'on', 'usually', 'good', 'by', 'situated', 'only', 'consistent', 'patria', 'was', 'had', 'pretty', 'in', 'does', 'when', 'of', 'come', 'it', 'when', 'with', 'of', 'taunts', 'bloody', 'such', 'even', 'quickly', 'br', 'of', 'performances', 'offer', 'such', 'even', 'meant', 'are', 'of', 'shin', 'when', 'it', 'of', 'come', 'br', 'of', 'left', 'bloody', 'when', 'it', 'of', 'come', 'br', 'of', 'conjure', 'are', 'of', 'late', 'such', 'is', 'performances', 'shin', 'such', 'stupid', 'want', 'has', 'so', 'ireland', 'absurd', 'corner', 'lohan', 't', 'sorry', 'film', 'of', 'obsequious', 'mother', 'to', 'of', '43', 'it', 'for', 'woods', 'in', \"lena's\", 'facelift', 'everyone', 'as', 'it', '1913', 'such', 'such', 'story', 'of', 'shin', 'might', 'just', 'if', 'be', 'everyone', 'for', 'utterly', 'with', 'best', 'forties', 'movie', 'but', 'attempts', 'sloan', 'was', 'personality', 'as', 'on', 'most', 'all', 'with', 'this', 'that', 'to', 'extremely', 'but', 'greg', 'films', 'situation', 'those', 'to', 'people', 'stupid', 'we', 'when', 'was', 'kids', 'in', 'eventually', 'was', 'rather', 'out', 'is', 'news', 'this', 'husband', 'keeps', 'like', 'developed', 'characters', 'photography']\n",
      "---label---\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "word2id = imdb.get_word_index()\n",
    "id2word = {i: word for word, i in word2id.items()}\n",
    "print('---review with words---')\n",
    "print([id2word.get(i, ' ') for i in X_train[15000]])\n",
    "print('---label---')\n",
    "print(y_train[15000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure that all input documents are the same length, we will trim each review down to 500 words. For reviews shorter than 500 words, we will pad them with zeros. We will use the pad_sequence() function to achieve this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    sequences = X_train, \n",
    "    maxlen=500,\n",
    "    dtype=\"int32\",\n",
    "    padding=\"pre\",\n",
    "    truncating=\"pre\",\n",
    "    value=0.0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    sequences = X_test, \n",
    "    maxlen=500,\n",
    "    dtype=\"int32\",\n",
    "    padding=\"pre\",\n",
    "    truncating=\"pre\",\n",
    "    value=0.0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the vocabulary size(input size) in our data set, which is required for our embedding layer, we need to find the max integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max for train set:  88586\n"
     ]
    }
   ],
   "source": [
    "print(\"Max for train set: \", X_train.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our max integer is 88586, therefore, our vocabulary size is 88586 + 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and compile model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first layer is an Embedding Layer, which turns positive integers (indexes) into dense vectors of fixed size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=88587,\n",
    "                    output_dim=64,\n",
    "                    input_length=500))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 500, 64)           5669568   \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 5,702,657\n",
      "Trainable params: 5,702,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Curtis\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 310s 12ms/step - loss: 0.2476 - accuracy: 0.6799\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 315s 13ms/step - loss: 0.2046 - accuracy: 0.7584\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 319s 13ms/step - loss: 0.1588 - accuracy: 0.8248\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 326s 13ms/step - loss: 0.1365 - accuracy: 0.8549\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 323s 13ms/step - loss: 0.1249 - accuracy: 0.8703\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 415s 17ms/step - loss: 0.1208 - accuracy: 0.8760\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 500s 20ms/step - loss: 0.1126 - accuracy: 0.8847\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 503s 20ms/step - loss: 0.1120 - accuracy: 0.8867\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 507s 20ms/step - loss: 0.1126 - accuracy: 0.8860\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 496s 20ms/step - loss: 0.1063 - accuracy: 0.8930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2ef0cbd7c08>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=35, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 176s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8458799719810486"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "scores[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training model has an accuracy of about 89% and our test accuracy is about 84%. Our model performs very well on the test data.\n",
    "\n",
    "Note: Increasing epoch improves accuracy up to a certain point, however, it also significantly icreases the total training time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use our model to make predictions on the data set. This will be done by passing a few reviews through our model and checking if they predicted the reviews correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=model.predict_classes(X_test)\n",
    "predict_classes=predict.reshape(len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function below is used to convert reviews back to words,\n",
    "# as well as pad the reviews\n",
    "def get_original_text(i):\n",
    "    word_to_id = imdb.get_word_index()\n",
    "    word_to_id = {k:(v+3) for k, v in word_to_id.items()}\n",
    "    word_to_id[\"<PAD>\"] = 0\n",
    "    word_to_id[\"<START>\"] = 1\n",
    "    word_to_id[\"<UNK>\"] = 2\n",
    "\n",
    "    id_to_word = {value:key for key, value in word_to_id.items()}\n",
    "    return ' '.join(id_to_word[id] for id in X_test[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "SentimentDict={1:'positive', 0:'negative'}\n",
    "def display_test_sentiment(i):\n",
    "    print(get_original_text(i))\n",
    "    print('label: ', SentimentDict[y_test[i]], ', prediction: ', SentimentDict[predict_classes[i]])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we pass three seperate reviews through our model. Below we show the label the review, as well as the predicted label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <START> i generally love this type of movie however this time i found myself wanting to kick the screen since i can't do that i will just complain about it this was absolutely idiotic the things that happen with the dead kids are very cool but the alive people are absolute idiots i am a grown man pretty big and i can defend myself well however i would not do half the stuff the little girl does in this movie also the mother in this movie is reckless with her children to the point of neglect i wish i wasn't so angry about her and her actions because i would have otherwise enjoyed the flick what a number she was take my advise and fast forward through everything you see her do until the end also is anyone else getting sick of watching movies that are filmed so dark anymore one can hardly see what is being filmed as an audience we are impossibly involved with the actions on the screen so then why the hell can't we have night vision\n",
      "label:  negative , prediction:  negative\n"
     ]
    }
   ],
   "source": [
    "display_test_sentiment(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <START> i can't get this flick off my brain it's definitely totally different than anything that's out there i've seen a ton of movies over the holidays and while some are okay nothing really rocked my world the way did there is just something way cool about the actors and the way that they put the film together it's like there is really scary stuff mixed with with some pretty f ing hilarious black humour franco is great but the older rough dude steals the show in a few scenes like when he punches the kid out in the dirt grave i guess some politically won't appreciate the vibe don't bring your grandma but it is totally awesome the thing that's best is the style there is some really serious stuff mixed with super interesting footage of the road the movie really makes you sad and scared in parts but it also spins your head with what is happening and the way it is filmed wtf is up with the world sooo many critics are raving about all these supposedly revolutionary ground breaking films and when you see them they're boring and predictable and not all that i don't get it because there are a lot of other better choices blind spot is really kinda great because it gives you thrills and chills and major upcoming star power but does it in a way that is completely fresh and definitely totally rad\n",
      "label:  positive , prediction:  positive\n"
     ]
    }
   ],
   "source": [
    "display_test_sentiment(87)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <START> george zucco was like boris karloff in the fact no matter how poor the film he appeared in was he would always maintain a sense of dignity and turn in a fine performance the mad monster is no exception to that rule it is by all standards a poor if entertaining film the filmmakers obviously didn't know how to make the most of their low budget and the script seems as if it was turned out in one or two days still zucco is fine and believable as the mad scientist br br the film itself is enjoyable on a camp level normal horror movie fans for the most part won't take a liking to prc films however these poverty row productions have a small but loyal cult following occasionally they would rise above their limitations with detour being the best example of this usually they looked like this for all its technically poor qualities the mad monster is an amusing enough way to kill a rainy afternoon the dvd from retromedia is recommended as it pairs this with another prc production the black raven the original theatrical trailer and best of all an interview with glenn strange talking about his role in this movie 4 10\n",
      "label:  negative , prediction:  negative\n"
     ]
    }
   ],
   "source": [
    "display_test_sentiment(1206)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "- To ensure that our input data was equal sizes, we limited each review to 500 words. For reviews that had less than 500 words, we padded those reviews with zeros using Keras' pad_sequence() function.\n",
    "- We included an Embedding layer in our RNN, which turns positive integers (indexes) into dense vectors of fixed size.\n",
    "- Using a batch size 35 and epoch size of 10, our train accuracy was about 89% and our test accuracy was about 85%.\n",
    "- When using our model to predict the sentiment of 3 reviews, it predicted all 3 correctly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
